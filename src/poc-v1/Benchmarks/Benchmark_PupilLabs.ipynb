{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import tilemapbase as tmb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pluma.stream.georeference import Georeference\n",
    "from pluma.stream.ubx import _UBX_MSGIDS\n",
    "from pluma.schema import Dataset\n",
    "\n",
    "## Notebook plotting\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "## Figure export parameters\n",
    "new_rc_params = {'text.usetex': False,\n",
    "\"svg.fonttype\": 'none'\n",
    "}\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(new_rc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Important notes\n",
    "# It appears the the end of the video file (.avi) is corrupted due to the decoding process. As a result we should crop the 0mq data to the same length as the video file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_root_folder = r'C:\\Users\\neurogears\\Desktop\\2023_05_15_23_35_14'\n",
    "from benchmark_schemas import build_benchmarkschema_pupillabs\n",
    "\n",
    "dataset = Dataset(\n",
    "    stream_root_folder,\n",
    "    datasetlabel=\"PupilLabs_Benchmark\",\n",
    "    georeference= Georeference(),\n",
    "    schema=build_benchmarkschema_pupillabs)\n",
    "dataset.populate_streams(autoload=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check corrupted frames\n",
    "video_path = stream_root_folder + r'\\pupil_video.avi'\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) # returns the correct number of frames\n",
    "print('Number of frames: ', frame_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_counter = dataset.streams.PupilLabs.Counter.DecodedFrames\n",
    "#decoded_counter = dataset.streams.PupilLabs.Counter.RawFrames\n",
    "\n",
    "decoded_counter.data = decoded_counter.data[~decoded_counter.data.index.duplicated(keep='first')]\n",
    "decoded_counter.data = decoded_counter.data[~(decoded_counter.data == 1)]\n",
    "\n",
    "## Load luminance data tracked from the video\n",
    "lum = pd.read_csv(stream_root_folder + r'\\pupil_video_lum.csv', header=None, names=['lum'])\n",
    "decoded_counter.data[\"lum\"] = lum.values\n",
    "decoded_counter.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Find rising edges in the video\n",
    "threshold = 70\n",
    "ttl = (decoded_counter.data['lum'] > threshold).astype(int)\n",
    "rising_edge_camera = decoded_counter.data.index[ttl.diff() == 1]\n",
    "\n",
    "\n",
    "## find rising edges in harp\n",
    "dataset.streams.BioData.Set.data = dataset.streams.BioData.Set.data[~dataset.streams.BioData.Set.data.index.duplicated(keep='first')]\n",
    "bit_mask = 1024\n",
    "rising_edge_harp = dataset.streams.BioData.Set.data[dataset.streams.BioData.Set.data & bit_mask > 0].index.values\n",
    "print((len(rising_edge_camera), len(rising_edge_harp)))\n",
    "\n",
    "## There seems to be an extra ttl at the start and many at the end. Lets realign the data...\n",
    "rising_edge_harp = np.delete(rising_edge_harp, 0)\n",
    "rising_edge_harp = rising_edge_harp[0:len(rising_edge_camera)]\n",
    "print((len(rising_edge_camera), len(rising_edge_harp)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (9,6))\n",
    "\n",
    "plt.plot(np.diff(rising_edge_camera) / 1e9, label='camera')\n",
    "plt.plot(np.diff(rising_edge_harp) / 1e9, label='harp')\n",
    "plt.show()\n",
    "\n",
    "delta_t = rising_edge_camera - rising_edge_harp\n",
    "delta_t = -delta_t / np.timedelta64(1, 'ms')\n",
    "\n",
    "plt.figure(figsize= (9,6))\n",
    "plt.plot(delta_t)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize= (9,6))\n",
    "plt.hist(delta_t, bins = 25, color= \"Teal\")\n",
    "plt.xlabel('Latency (ms)')\n",
    "plt.ylabel('Counts')\n",
    "#plt.xlim((0,5000))\n",
    "plt.title(f'Pupil tracking latency benchmark\\n$\\mu = {np.mean(delta_t):.2f}, \\sigma = {np.std(delta_t):.2f},$ [min:max] = [{np.min(delta_t):.2f}:{np.max(delta_t):.2f}]')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09bd21bb92291494554824029e1a9dff7dc56aa6d478169471a2232705d1a524"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
