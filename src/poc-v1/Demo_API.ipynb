{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import tilemapbase as tmb\n",
    "\n",
    "from pluma.stream.georeference import Georeference\n",
    "from pluma.stream.ubx import _UBX_MSGIDS\n",
    "from pluma.schema import Dataset\n",
    "\n",
    "## Notebook plotting\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "## Figure export parameters\n",
    "new_rc_params = {'text.usetex': False,\n",
    "\"svg.fonttype\": 'none'\n",
    "}\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(new_rc_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the paths to the dataset and build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_FROM_REMOTE = True\n",
    "root = r\"C:\\Users\\neurogears\\Desktop\"\n",
    "\n",
    "stream_root_folder = ''  # Path to the dataset. Can be local or remote.\n",
    "\n",
    "dataset = Dataset(stream_root_folder, datasetlabel=\"FMUL_\" + stream_root_folder.split(\"\\\\\")[-1], georeference= Georeference())  # Create a Dataset object that will contain the ingested data.\n",
    "dataset.populate_streams(autoload=False)  # Add the \"schema\" that we want to load to our Dataset. If we want to load the whole dataset automatically, set autoload to True.\n",
    "\n",
    "if LOAD_FROM_REMOTE:\n",
    "# To load a single stream, we can set the autoload property to \"True\" and use the Dataset.reload_streams method. In this case, we will load all streams by default\n",
    "    if True:\n",
    "        dataset.streams.EEG.autoload = True\n",
    "        dataset.streams.UBX.autoload = True\n",
    "        dataset.reload_streams(force_load=False)\n",
    "    # For now, we will build the whole dataset:\n",
    "    else:\n",
    "        dataset.reload_streams(force_load=True)  # We will just load every single stream at the same time. This might take a while if loading from AWS\n",
    "        dataset.add_georeference_and_calibrate()\n",
    "        dataset.export_dataset(filename=f\"{root}\\dataset.pickle\") # We can export the dataset as a .pickle file.\n",
    "\n",
    "    # Some warnings will be printed if some sensors were not acquired during the experiment. These are normal and can be usually ignored.\n",
    "\n",
    "# In order to not having to run this routine multiple times, the output of the ingestion can be saved as a pickle file to be loaded later. E.g.:\n",
    "else:\n",
    "    dataset = Dataset.import_dataset(f\"{root}\\dataset.pickle\")  # ... and reimport it at a later point.\n",
    "print(f\"Dataset: {dataset} loaded successfully, and {'not' if not dataset.has_calibration else 'sucessfully'} calibrated.\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset structure\n",
    "The Dataset class follows the following structure:\n",
    "```\n",
    "Dataset/\n",
    "├─ rootfolder\n",
    "├─ datasetlabel\n",
    "├─ streams/\n",
    "├─ georeference/\n",
    "```\n",
    "\n",
    " - `rootfolder` and `datasetlabel` are properties that store the location and label of the dataset, respectively.\n",
    " - `streams` is a `DotMap` structure with the initialized schema and, if loaded, all the data. The data of each stream can be generally accessed using `dataset.Stream.data`. Additionally, the Streams can be easily navigated using the \".\" (dot) notation to access different, potentially nested, relevant fields.\n",
    " - `georeference` stores the DataFrame necessary to \"geotag\" sensor data (*i.e.* to cross-reference in time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the data from a sensor:\n",
    "SensorData = dataset.streams.TK.Humidity.Humidity #  Reference one arbitrary sensor data\n",
    "# Most of the data is in a DataFrame format. Indexed by a column that indicates the time at which the sample was acquired.\n",
    "print(SensorData.data.head(5))\n",
    "plt.figure()\n",
    "plt.plot(SensorData.data)\n",
    "plt.xlabel(\"Time (UTC)\")\n",
    "plt.ylabel(\"Sensor Value (a.u.)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity a general method can be used to attempt to plot the data inside a stream:\n",
    "dataset.streams.TK.Humidity.Humidity.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization:\n",
    "\n",
    "We are not in a position where we can visualize data in both time and space. The following cells will demo this affordance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first time you run tilemapbase library, you will need to initiate a cache structure\n",
    "# Initialize tilemapbase cache (run this only once)\n",
    "if False:\n",
    "    import tilemapbase as tmb\n",
    "    tmb.init(create=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will plot the spatial data colorcoded by time\n",
    "\n",
    "fig = dataset.showmap(colorscale_override=dataset.georeference.spacetime.index,\n",
    "                      cmap = \"jet\",\n",
    "                      markersize= 5, figsize = (10,10)\n",
    "                      )\n",
    "fig.get_axes()[0].set_title(dataset.datasetlabel)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pluma.preprocessing.resampling import resample_temporospatial\n",
    "from pluma.export.maps import showmap\n",
    "\n",
    "# resample_temporospatial() resamples data in time and space using a dataset georeference. By default, it resamples the data to 2s bins\n",
    "\n",
    "resampled = resample_temporospatial(dataset.streams.TK.AirQuality.Temperature.data,\n",
    "                                    dataset.georeference,\n",
    "                                    sampling_dt=datetime.timedelta(seconds = 2))\n",
    "\n",
    "\n",
    "tiles = tmb.tiles.Stamen_Watercolour # We can change how the map looks by passing an optional \"tiles\" argument\n",
    "fig = showmap(resampled,\n",
    "              figsize=(10,10),\n",
    "              tiles=tiles)\n",
    "fig.get_axes()[0].set_title(dataset.datasetlabel)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes additional preprocessing might be required. As an example, when calculating heart rate from the ECG raw signal.\n",
    "\n",
    "from pluma.preprocessing.ecg import heartrate_from_ecg\n",
    "\n",
    "hr,_ = heartrate_from_ecg(dataset.streams.BioData.ECG,\n",
    "                                         fs = 250, max_heartrate_bpm = 250.0,\n",
    "                                        peak_height = 800, smooth_win = 10) ## Calculates HR from ecg raw signal\n",
    "\n",
    "resampled = resample_temporospatial(hr, dataset.georeference,\n",
    "                                           sampling_dt = datetime.timedelta(seconds = 4)) #Resample\n",
    "fig = showmap(resampled, figsize=(10,10), cmap = 'brg', markersize = 20 ,\n",
    "                                           tiles = tmb.tiles.Stamen_Toner_Hybrid)\n",
    "fig.get_axes()[0].set_title(dataset.datasetlabel)\n",
    "fig.show()\n",
    "\n",
    "## Plot it in time for comparison\n",
    "fig, axs = plt.subplots(2,2)\n",
    "fig.set_size_inches((10,4))\n",
    "axs[0,0].plot(resampled.Data,  c = [0.1, 0.1, 0.1], lw = 0.5)\n",
    "axs[0,0].set_xlabel('Time')\n",
    "axs[0,0].set_ylabel('HR (BPM)')\n",
    "\n",
    "axs[0,1].plot(dataset.streams.Accelerometer.data[\"Accl.X\"], c = [0.1, 0.1, 0.1], lw = 0.5)\n",
    "axs[0,1].set_xlabel('Time')\n",
    "axs[0,1].set_ylabel('Acceleration (G)')\n",
    "\n",
    "## Plot it in time for comparison\n",
    "axs[1,0].plot(dataset.streams.TK.AirQuality.Temperature.data/100,  c = [0.1, 0.1, 0.1], lw = 0.5)\n",
    "axs[1,0].set_xlabel('Time')\n",
    "axs[1,0].set_ylabel('Temperature (C)')\n",
    "\n",
    "axs[1,1].plot(dataset.streams.Accelerometer.data[\"Orientation.X\"],  c = [0.1, 0.1, 0.1], lw = 0.5)\n",
    "axs[1,1].set_xlabel('Time')\n",
    "axs[1,1].set_ylabel('Torso orientation (Deg)')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparison of HR given by Empatica and raw ECG signal:\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(hr, label = 'ECG')\n",
    "plt.plot(dataset.streams.Empatica.data.E4_Hr['Value'], label = 'Empatica')\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"HR(bpm)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.streams.Empatica.data.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export streams to csv\n",
    "dataset.streams.TK.AirQuality.Temperature.export_to_csv(\"root\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ecities')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48653fe3dda52384a74b4629056b2ddac10114526fe1f868c0a7cdd8bc2dd6c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
