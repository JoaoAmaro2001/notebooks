{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import os\n",
    "import utils.for_setpath as path\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pluma-python API  \n",
    "from modules import *\n",
    "from pluma.schema.outdoor import build_schema\n",
    "\n",
    "# Load data\n",
    "datapicker = create_datapicker(path=r'Z:\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\data\\OE009',schema=build_schema)\n",
    "display(datapicker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export empatica to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils.for_setpath as path\n",
    "\n",
    "# Function to export Empatica and ECG data to csv\n",
    "def empatica_and_ecg_to_csv(datapicker, outdir):\n",
    "    \n",
    "    from pluma.preprocessing.ecg import heartrate_from_ecg\n",
    "    \n",
    "    # Get LSL markers\n",
    "    lsl_markers = datapicker.dataset.streams.EEG.server_lsl_marker[datapicker.dataset.streams.EEG.server_lsl_marker.MarkerIdx>35000]\n",
    "\n",
    "    # # Get heartrate from ECG (ERROR -> TypeError: 'DotMap' object is not callable)\n",
    "    # ecg_hr = heartrate_from_ecg(ecg = datapicker.dataset.streams.BioData.ECG,\n",
    "    #                                      sample_rate = 50, bpmmax = 200)\n",
    "    \n",
    "    # Save to csv\n",
    "    lsl_markers.to_csv(outdir+r'\\lsl_markers.csv')\n",
    "    # ecg_hr.to_csv(outdir+r'\\ecg_hr.csv')\n",
    "    # datapicker.dataset.streams.BioData.ECG.data.Value0.to_frame().to_csv(outdir+r'\\ecg.csv')\n",
    "    datapicker.dataset.streams.Empatica.data.E4_Gsr.to_csv(outdir+r'\\e4_gsr.csv')\n",
    "    datapicker.dataset.streams.Empatica.data.E4_Temperature.to_csv(outdir+r'\\e4_temp.csv')\n",
    "    datapicker.dataset.streams.Empatica.data.E4_Ibi.to_csv(outdir+r'\\e4_ibi.csv')\n",
    "    datapicker.dataset.streams.Empatica.data.E4_Bvp.to_csv(outdir+r'\\e4_bvp.csv')\n",
    "    datapicker.dataset.streams.Empatica.data.E4_Acc.to_csv(outdir+r'\\e4_acc.csv')\n",
    "    datapicker.dataset.streams.Empatica.data.E4_Hr.to_csv(outdir+r'\\e4_hr.csv')\n",
    "\n",
    "# Export data to csv\n",
    "csv_outdir = os.path.join(path.sourcedata, 'supp', 'stress_csv', 'sub-OE009', 'ses-Lapa')\n",
    "if not os.path.exists(csv_outdir): \n",
    "    os.makedirs(csv_outdir)\n",
    "empatica_and_ecg_to_csv(datapicker, csv_outdir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export metrics as 1Hz data stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "import biosppy\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "def process_empatica_data(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Processes EDA and related physiological data from CSV files,\n",
    "    resamples to 1Hz, and saves the combined data to a CSV file.\n",
    "    All generated figures are saved to the output directory.\n",
    "\n",
    "    Parameters:\n",
    "    - input_dir: Directory containing the input CSV files.\n",
    "    - output_dir: Directory where the output CSV and figures will be saved.\n",
    "\n",
    "    Output:\n",
    "    - Saves 'data_all_1Hz.csv' to the output directory.\n",
    "    - Saves all generated figures to the output directory.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Set default plotting parameters\n",
    "    plt.rcParams['agg.path.chunksize'] = 10000\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "    # Sampling frequencies\n",
    "    fs_bvp = 64\n",
    "    fs_eda = 4\n",
    "\n",
    "    # Load data from CSV files (excluding ecg_hr.csv and ecg.csv)\n",
    "    print(\"Loading data...\")\n",
    "    bvp_subj = pd.read_csv(os.path.join(input_dir, 'e4_bvp.csv'))\n",
    "    ibi_subj = pd.read_csv(os.path.join(input_dir, 'e4_ibi.csv'))\n",
    "    eda_subj = pd.read_csv(os.path.join(input_dir, 'e4_gsr.csv'))\n",
    "    hr_subj = pd.read_csv(os.path.join(input_dir, 'e4_hr.csv'))\n",
    "    acc_subj = pd.read_csv(os.path.join(input_dir, 'e4_acc.csv'))\n",
    "    temp_subj = pd.read_csv(os.path.join(input_dir, 'e4_temp.csv'))\n",
    "\n",
    "    # Process datetime columns\n",
    "    print(\"Processing datetime columns...\")\n",
    "    eda_subj['DateTime'] = pd.to_datetime(eda_subj['E4_Seconds'].str[:-3], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    bvp_subj['DateTime'] = pd.to_datetime(bvp_subj['E4_Seconds'].str[:-3], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    ibi_subj['DateTime'] = pd.to_datetime(ibi_subj['E4_Seconds'].str[:-3], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    hr_subj['DateTime'] = pd.to_datetime(hr_subj['E4_Seconds'].str[:-3], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    acc_subj['DateTime'] = pd.to_datetime(acc_subj['E4_Seconds'].str[:-3], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    temp_subj['DateTime'] = pd.to_datetime(temp_subj['E4_Seconds'].str[:-3], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "\n",
    "    # Rename columns for consistency\n",
    "    eda_subj.rename(columns={'Value': 'Values'}, inplace=True)\n",
    "    bvp_subj.rename(columns={'Value': 'Values'}, inplace=True)\n",
    "    ibi_subj.rename(columns={'Value': 'Values'}, inplace=True)\n",
    "    hr_subj.rename(columns={'Value': 'Values'}, inplace=True)\n",
    "    acc_subj.rename(columns={'Value': 'Values'}, inplace=True)\n",
    "    temp_subj.rename(columns={'Value': 'Values'}, inplace=True)\n",
    "\n",
    "    # Compute accelerometer magnitude\n",
    "    acc_subj['Magnitude'] = np.sqrt(acc_subj['AccX']**2 + acc_subj['AccY']**2 + acc_subj['AccZ']**2)\n",
    "\n",
    "    # Filter EDA signal\n",
    "    print(\"Filtering EDA signal...\")\n",
    "    eda_subj['Filtered'] = scipy.signal.savgol_filter(eda_subj['Values'], window_length=11, polyorder=5)\n",
    "    b, a = scipy.signal.butter(5, 0.05, btype='highpass', fs=fs_eda)\n",
    "    eda_subj['NEW_EDA'] = scipy.signal.filtfilt(b, a, eda_subj['Filtered'])\n",
    "\n",
    "    # Plot EDA signals\n",
    "    print(\"Plotting EDA signals...\")\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(eda_subj['DateTime'], eda_subj['Values'], label='Raw EDA')\n",
    "    plt.plot(eda_subj['DateTime'], eda_subj['Filtered'], label='Filtered EDA')\n",
    "    plt.plot(eda_subj['DateTime'], eda_subj['NEW_EDA'], label='High-pass Filtered EDA')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('EDA Value')\n",
    "    plt.title('EDA Signal Processing')\n",
    "    plt.savefig(os.path.join(output_dir, 'eda_signals.png'), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Process IBI data\n",
    "    print(\"Processing IBI data...\")\n",
    "    ibi_subj['IBI'] = ibi_subj['Values']\n",
    "    ibi_subj['bpm'] = 60 / ibi_subj['IBI']\n",
    "\n",
    "    # Plot HR signals (from IBI and E4 HR)\n",
    "    print(\"Plotting HR signals...\")\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(hr_subj['DateTime'], hr_subj['Values'], label='E4 HR')\n",
    "    plt.plot(ibi_subj['DateTime'], ibi_subj['bpm'], label='E4 IBI Heart Rate')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Heart Rate (bpm)')\n",
    "    plt.title('Heart Rate Comparison (E4 HR and E4 IBI)')\n",
    "    plt.savefig(os.path.join(output_dir, 'hr_signals.png'), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Resample data to 1Hz\n",
    "    print(\"Resampling data to 1Hz...\")\n",
    "\n",
    "    # Function to resample numeric columns only\n",
    "    def resample_numeric(df, datetime_col='DateTime', freq='1S'):\n",
    "        df_numeric = df.select_dtypes(include=[np.number])\n",
    "        df_numeric[datetime_col] = df[datetime_col]\n",
    "        df_numeric = df_numeric.set_index(datetime_col).resample(freq).mean().reset_index()\n",
    "        return df_numeric\n",
    "\n",
    "    data_ibi = resample_numeric(ibi_subj)\n",
    "    data_hr = resample_numeric(hr_subj)\n",
    "    data_temp = resample_numeric(temp_subj)\n",
    "    data_eda = resample_numeric(eda_subj)\n",
    "    data_acc = resample_numeric(acc_subj)\n",
    "    data_bvp = resample_numeric(bvp_subj)\n",
    "\n",
    "    # Merge all data into a single DataFrame\n",
    "    print(\"Merging data...\")\n",
    "    data_all = data_hr[['DateTime', 'Values']].rename(columns={'Values': 'E4_HR'})\n",
    "    data_all = pd.merge(data_all, data_ibi[['DateTime', 'bpm']].rename(columns={'bpm': 'E4_HR_IBI'}), on='DateTime', how='outer')\n",
    "    data_all = pd.merge(data_all, data_temp[['DateTime', 'Values']].rename(columns={'Values': 'TEMP'}), on='DateTime', how='outer')\n",
    "    data_all = pd.merge(data_all, data_eda[['DateTime', 'Values', 'NEW_EDA']].rename(columns={'Values': 'EDA_RAW', 'NEW_EDA': 'EDA_PHASIC'}), on='DateTime', how='outer')\n",
    "    data_all = pd.merge(data_all, data_acc[['DateTime', 'AccX', 'AccY', 'AccZ', 'Magnitude']], on='DateTime', how='outer')\n",
    "    data_all = pd.merge(data_all, data_bvp[['DateTime', 'Values']].rename(columns={'Values': 'BVP_Values'}), on='DateTime', how='outer')\n",
    "\n",
    "    # Plot merged data\n",
    "    print(\"Plotting merged data...\")\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(data_all['DateTime'], data_all['E4_HR'], label='E4 HR')\n",
    "    plt.plot(data_all['DateTime'], data_all['E4_HR_IBI'], label='E4 HR from IBI')\n",
    "    plt.plot(data_all['DateTime'], data_all['EDA_RAW'], label='EDA Raw')\n",
    "    plt.plot(data_all['DateTime'], data_all['TEMP'], label='Temperature')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('Merged Physiological Data')\n",
    "    plt.savefig(os.path.join(output_dir, 'merged_data.png'), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Save combined data to CSV\n",
    "    print(\"Saving combined data to CSV...\")\n",
    "    data_all.to_csv(os.path.join(output_dir, 'data_all_1Hz.csv'), index=False)\n",
    "\n",
    "    print(\"Processing complete. All figures and CSV file saved to the output directory.\")\n",
    "\n",
    "\n",
    "# Process Empatica data\n",
    "input_directory = os.path.join(path.sourcedata, 'supp', 'stress_csv', 'sub-OE009', 'ses-Lapa')\n",
    "output_directory = os.path.join(input_directory, '_1hz')\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "process_empatica_data(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations with climate data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Empatica data...\n",
      "Locating climate data CSV file...\n",
      "Climate data CSV file found: Z:\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\supp\\log2\\sub-OE009\\ses-Lisbon_Lapa_sub-OE102009_2024-05-02T132016Z\\sub-OE009_ses-Lisbon_Lapa_sub-OE102009_2024-05-02T132016Z_geodata_processed.csv\n",
      "Reading climate data...\n",
      "Combining 'DateTime' and 'second' to create full datetime with seconds...\n",
      "Climate data 'DateTime' dtype: datetime64[ns]\n",
      "Merging Empatica data with climate data...\n",
      "Performing correlations between 'utci' and Empatica variables...\n",
      "Saving correlation results...\n",
      "Correlation analysis complete. Results saved to the output directory.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import pearsonr, spearmanr, linregress\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set plotting parameters\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "# Define paths and session information\n",
    "# Update these variables according to your directory structure\n",
    "output_dir = os.path.join(path.sourcedata, 'supp', 'correlation', 'sub-OE009', 'ses-Lapa')         # Replace with your output directory\n",
    "empatica_data_path = os.path.join(path.sourcedata, 'supp', 'stress_csv', 'sub-OE009', 'ses-Lapa', '_1hz', 'data_all_1Hz.csv')\n",
    "sourcedata_path = os.path.join(path.sourcedata, 'supp') # Replace with the path to 'sourcedata' directory\n",
    "session_name = 'Lapa'                            # Replace with your session name\n",
    "subject_folder = 'sub-OE009'           # Replace with your subject folder name\n",
    "\n",
    "# Ensure output directory exists\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Load Empatica data\n",
    "print(\"Loading Empatica data...\")\n",
    "empatica_data = pd.read_csv(empatica_data_path, parse_dates=['DateTime'])\n",
    "\n",
    "# Ensure 'DateTime' is in datetime format\n",
    "if empatica_data['DateTime'].dtype != 'datetime64[ns]':\n",
    "    empatica_data['DateTime'] = pd.to_datetime(empatica_data['DateTime'], errors='coerce')\n",
    "\n",
    "# Remove any rows with NaT in 'DateTime'\n",
    "empatica_data = empatica_data.dropna(subset=['DateTime'])\n",
    "\n",
    "# Floor to seconds to ensure alignment\n",
    "empatica_data['DateTime'] = empatica_data['DateTime'].dt.floor('S')\n",
    "\n",
    "# --- Climate Data Processing ---\n",
    "\n",
    "# Locate the climate data CSV file\n",
    "print(\"Locating climate data CSV file...\")\n",
    "log2_path = os.path.join(sourcedata_path, 'log2')\n",
    "subject_path = os.path.join(log2_path, subject_folder)\n",
    "\n",
    "# Find session folder containing the session name\n",
    "session_folder = None\n",
    "for folder in os.listdir(subject_path):\n",
    "    if session_name in folder:\n",
    "        session_folder = folder\n",
    "        break\n",
    "\n",
    "if session_folder is None:\n",
    "    print(f\"Session folder containing '{session_name}' not found in {subject_path}.\")\n",
    "else:\n",
    "    session_path = os.path.join(subject_path, session_folder)\n",
    "\n",
    "    # Find the CSV file containing 'geodata_processed' in the filename\n",
    "    climate_csv_file = None\n",
    "    for file in os.listdir(session_path):\n",
    "        if 'geodata_processed' in file and file.endswith('.csv'):\n",
    "            climate_csv_file = file\n",
    "            break\n",
    "\n",
    "    if climate_csv_file is None:\n",
    "        print(f\"No CSV file containing 'geodata_processed' found in {session_path}.\")\n",
    "    else:\n",
    "        climate_csv_path = os.path.join(session_path, climate_csv_file)\n",
    "        print(f\"Climate data CSV file found: {climate_csv_path}\")\n",
    "\n",
    "        # Read the climate data CSV file\n",
    "        print(\"Reading climate data...\")\n",
    "        climate_data = pd.read_csv(climate_csv_path)\n",
    "\n",
    "        # Ensure datetime column is parsed correctly\n",
    "        if 'DateTime' in climate_data.columns:\n",
    "            climate_data['DateTime'] = pd.to_datetime(climate_data['DateTime'], errors='coerce')\n",
    "        else:\n",
    "            print(\"No 'DateTime' column found in climate data. Please ensure the CSV contains datetime information.\")\n",
    "            climate_data = None\n",
    "\n",
    "        # Remove any rows with NaT in 'DateTime'\n",
    "        if climate_data is not None:\n",
    "            climate_data = climate_data.dropna(subset=['DateTime'])\n",
    "\n",
    "        # Check if 'utci' column exists\n",
    "        if climate_data is not None and 'utci' not in climate_data.columns:\n",
    "            print(\"'utci' column not found in climate data.\")\n",
    "            climate_data = None\n",
    "\n",
    "        if climate_data is not None:\n",
    "            # Check if 'second' column exists\n",
    "            if 'second' in climate_data.columns:\n",
    "                # Combine 'DateTime' and 'second' to create a full datetime with seconds\n",
    "                print(\"Combining 'DateTime' and 'second' to create full datetime with seconds...\")\n",
    "                # Floor 'DateTime' to the nearest minute\n",
    "                climate_data['DateTime'] = climate_data['DateTime'].dt.floor('min')\n",
    "                # Add 'second' column as timedelta\n",
    "                climate_data['DateTime'] += pd.to_timedelta(climate_data['second'], unit='s')\n",
    "                # Now 'DateTime' includes seconds\n",
    "            else:\n",
    "                print(\"'second' column not found in climate data.\")\n",
    "                climate_data = None\n",
    "\n",
    "            # Ensure 'DateTime' is in datetime format\n",
    "            if climate_data is not None and climate_data['DateTime'].dtype != 'datetime64[ns]':\n",
    "                climate_data['DateTime'] = pd.to_datetime(climate_data['DateTime'], errors='coerce')\n",
    "                climate_data = climate_data.dropna(subset=['DateTime'])\n",
    "\n",
    "            # Check data type\n",
    "            print(\"Climate data 'DateTime' dtype:\", climate_data['DateTime'].dtype)\n",
    "\n",
    "            # Proceed if 'DateTime' and 'utci' are available\n",
    "            if climate_data is not None:\n",
    "                # Merge Empatica data with climate data on 'DateTime'\n",
    "                print(\"Merging Empatica data with climate data...\")\n",
    "                combined_data = pd.merge(empatica_data, climate_data[['DateTime', 'utci']], on='DateTime', how='inner')\n",
    "\n",
    "                # Save the combined data to CSV with proper datetime formatting\n",
    "                combined_data.to_csv(os.path.join(output_dir, 'combined_data.csv'), index=False, date_format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "                # Perform correlations between 'utci' and Empatica variables\n",
    "                print(\"Performing correlations between 'utci' and Empatica variables...\")\n",
    "                empatica_vars = combined_data.select_dtypes(include=[np.number]).columns.drop('utci')\n",
    "                correlation_results = []\n",
    "\n",
    "                for var in empatica_vars:\n",
    "                    # Drop NaN values for the pair\n",
    "                    valid_data = combined_data[['utci', var]].dropna()\n",
    "                    if len(valid_data) < 2:\n",
    "                        print(f\"Not enough data to compute correlation between 'utci' and '{var}'.\")\n",
    "                        continue\n",
    "\n",
    "                    # Pearson correlation\n",
    "                    pearson_corr, pearson_p = pearsonr(valid_data['utci'], valid_data[var])\n",
    "\n",
    "                    # Spearman correlation\n",
    "                    spearman_corr, spearman_p = spearmanr(valid_data['utci'], valid_data[var])\n",
    "\n",
    "                    # Append results\n",
    "                    correlation_results.append({\n",
    "                        'Variable': var,\n",
    "                        'Pearson_Correlation': pearson_corr,\n",
    "                        'Pearson_p_value': pearson_p,\n",
    "                        'Spearman_Correlation': spearman_corr,\n",
    "                        'Spearman_p_value': spearman_p\n",
    "                    })\n",
    "\n",
    "                    # Plot scatter plot with best-fit line\n",
    "                    plt.figure(figsize=(8, 6))\n",
    "\n",
    "                    # Scatter plot\n",
    "                    plt.scatter(valid_data['utci'], valid_data[var], color='blue', alpha=0.6, edgecolor='k', label='Data')\n",
    "\n",
    "                    # Best-fit line using linear regression (OLS)\n",
    "                    slope, intercept, r_value, p_value, std_err = linregress(valid_data['utci'], valid_data[var])\n",
    "                    x_vals = np.array([valid_data['utci'].min(), valid_data['utci'].max()])\n",
    "                    y_vals = intercept + slope * x_vals\n",
    "                    plt.plot(x_vals, y_vals, color='red', linewidth=2, label='OLS Linear Regression')\n",
    "\n",
    "                    # Aesthetics adjustments\n",
    "                    plt.xlabel('Universal Thermal Climate Index (UTCI)', fontsize=14)\n",
    "                    plt.ylabel(var, fontsize=14)\n",
    "                    plt.title(f'Relationship between {var} and UTCI', fontsize=16)\n",
    "                    plt.legend(frameon=False, fontsize=12)\n",
    "\n",
    "                    # Remove background grid and frame\n",
    "                    plt.gca().spines['top'].set_visible(False)\n",
    "                    plt.gca().spines['right'].set_visible(False)\n",
    "                    plt.gca().spines['left'].set_linewidth(1.5)\n",
    "                    plt.gca().spines['bottom'].set_linewidth(1.5)\n",
    "\n",
    "                    # Include Pearson and Spearman correlation coefficients and p-values in the plot\n",
    "                    textstr = '\\n'.join((\n",
    "                        r'Pearson $r=%.2f$ (p=%.2e)' % (pearson_corr, pearson_p),\n",
    "                        r'Spearman $\\rho=%.2f$ (p=%.2e)' % (spearman_corr, spearman_p)\n",
    "                    ))\n",
    "                    # Place text box in upper left in axes coords\n",
    "                    plt.text(0.05, 0.95, textstr, transform=plt.gca().transAxes, fontsize=12,\n",
    "                            verticalalignment='top', bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "\n",
    "                    # Tight layout for better spacing\n",
    "                    plt.tight_layout()\n",
    "\n",
    "                    # Save the figure\n",
    "                    plt.savefig(os.path.join(output_dir, f'scatter_{var}_vs_utci.png'), dpi=300)\n",
    "                    plt.close()\n",
    "\n",
    "                # Save correlation results to CSV\n",
    "                print(\"Saving correlation results...\")\n",
    "                correlation_df = pd.DataFrame(correlation_results)\n",
    "                correlation_df.to_csv(os.path.join(output_dir, 'correlation_results.csv'), index=False)\n",
    "\n",
    "                print(\"Correlation analysis complete. Results saved to the output directory.\")\n",
    "            else:\n",
    "                print(\"Climate data could not be processed due to missing 'DateTime', 'utci', or 'second' column.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests - Fixing ecg error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "import os\n",
    "import utils.for_setpath as path\n",
    "\n",
    "# For empatica\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "import biosppy\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "def process_empatica_data(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Processes EDA and related physiological data from CSV files,\n",
    "    resamples to 1Hz, and saves the combined data to a CSV file.\n",
    "    All generated figures are saved to the output directory.\n",
    "\n",
    "    Parameters:\n",
    "    - input_dir: Directory containing the input CSV files.\n",
    "    - output_dir: Directory where the output CSV and figures will be saved.\n",
    "\n",
    "    Output:\n",
    "    - Saves 'data_all_1Hz.csv' to the output directory.\n",
    "    - Saves all generated figures to the output directory.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Set default plotting parameters\n",
    "    plt.rcParams['agg.path.chunksize'] = 10000\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "    # Sampling frequencies\n",
    "    fs_bvp = 64\n",
    "    fs_eda = 4\n",
    "\n",
    "    # Load data from CSV files\n",
    "    print(\"Loading data...\")\n",
    "    ecg_hr = pd.read_csv(os.path.join(input_dir, 'ecg_hr.csv'))\n",
    "    ecg_signal = pd.read_csv(os.path.join(input_dir, 'ecg.csv'))\n",
    "    bvp_subj = pd.read_csv(os.path.join(input_dir, 'e4_bvp.csv'))\n",
    "    ibi_subj = pd.read_csv(os.path.join(input_dir, 'e4_ibi.csv'))\n",
    "    eda_subj = pd.read_csv(os.path.join(input_dir, 'e4_gsr.csv'))\n",
    "    hr_subj = pd.read_csv(os.path.join(input_dir, 'e4_hr.csv'))\n",
    "    acc_subj = pd.read_csv(os.path.join(input_dir, 'e4_acc.csv'))\n",
    "    temp_subj = pd.read_csv(os.path.join(input_dir, 'e4_temp.csv'))\n",
    "\n",
    "    # Process datetime columns\n",
    "    print(\"Processing datetime columns...\")\n",
    "    ecg_hr['DateTime'] = pd.to_datetime(ecg_hr['Seconds'].str[:-3], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    ecg_signal['DateTime'] = pd.to_datetime(ecg_signal['Seconds'].str[:-3], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    eda_subj['DateTime'] = pd.to_datetime(eda_subj['E4_Seconds'].str[:-3], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    bvp_subj['DateTime'] = pd.to_datetime(bvp_subj['E4_Seconds'].str[:-3], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    ibi_subj['DateTime'] = pd.to_datetime(ibi_subj['E4_Seconds'].str[:-3], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    hr_subj['DateTime'] = pd.to_datetime(hr_subj['E4_Seconds'].str[:-3], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    acc_subj['DateTime'] = pd.to_datetime(acc_subj['E4_Seconds'].str[:-3], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    temp_subj['DateTime'] = pd.to_datetime(temp_subj['E4_Seconds'].str[:-3], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "\n",
    "    # Rename columns for consistency\n",
    "    eda_subj.rename(columns={'Value': 'Values'}, inplace=True)\n",
    "    bvp_subj.rename(columns={'Value': 'Values'}, inplace=True)\n",
    "    ibi_subj.rename(columns={'Value': 'Values'}, inplace=True)\n",
    "    hr_subj.rename(columns={'Value': 'Values'}, inplace=True)\n",
    "    acc_subj.rename(columns={'Value': 'Values'}, inplace=True)\n",
    "    temp_subj.rename(columns={'Value': 'Values'}, inplace=True)\n",
    "\n",
    "    # Compute accelerometer magnitude\n",
    "    acc_subj['Magnitude'] = np.sqrt(acc_subj['AccX']**2 + acc_subj['AccY']**2 + acc_subj['AccZ']**2)\n",
    "\n",
    "    # Filter EDA signal\n",
    "    print(\"Filtering EDA signal...\")\n",
    "    eda_subj['Filtered'] = scipy.signal.savgol_filter(eda_subj['Values'], window_length=11, polyorder=5)\n",
    "    b, a = scipy.signal.butter(5, 0.05, btype='highpass', fs=fs_eda)\n",
    "    eda_subj['NEW_EDA'] = scipy.signal.filtfilt(b, a, eda_subj['Filtered'])\n",
    "\n",
    "    # Plot EDA signals\n",
    "    print(\"Plotting EDA signals...\")\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(eda_subj['DateTime'], eda_subj['Values'], label='Raw EDA')\n",
    "    plt.plot(eda_subj['DateTime'], eda_subj['Filtered'], label='Filtered EDA')\n",
    "    plt.plot(eda_subj['DateTime'], eda_subj['NEW_EDA'], label='High-pass Filtered EDA')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('EDA Value')\n",
    "    plt.title('EDA Signal Processing')\n",
    "    plt.savefig(os.path.join(output_dir, 'eda_signals.png'), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Process IBI data\n",
    "    print(\"Processing IBI data...\")\n",
    "    ibi_subj['IBI'] = ibi_subj['Values']\n",
    "    ibi_subj['bpm'] = 60 / ibi_subj['IBI']\n",
    "\n",
    "    # Process ECG HR data\n",
    "    ecg_hr['HeartRate'] = ecg_hr['HeartRate']\n",
    "\n",
    "    # Plot HR signals\n",
    "    print(\"Plotting HR signals...\")\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(ecg_hr['DateTime'], ecg_hr['HeartRate'], label='ECG Heart Rate')\n",
    "    plt.plot(ibi_subj['DateTime'], ibi_subj['bpm'], label='E4 IBI Heart Rate')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Heart Rate (bpm)')\n",
    "    plt.title('Heart Rate Comparison')\n",
    "    plt.savefig(os.path.join(output_dir, 'hr_signals.png'), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Resample data to 1Hz\n",
    "    print(\"Resampling data to 1Hz...\")\n",
    "    data_ecg_hr = ecg_hr.set_index('DateTime').resample(\"1S\").mean().reset_index()\n",
    "    data_ibi = ibi_subj.set_index('DateTime').resample(\"1S\").mean().reset_index()\n",
    "    data_temp = temp_subj.set_index('DateTime').resample(\"1S\").mean().reset_index()\n",
    "    data_eda = eda_subj.set_index('DateTime').resample(\"1S\").mean().reset_index()\n",
    "    data_acc = acc_subj.set_index('DateTime').resample(\"1S\").mean().reset_index()\n",
    "    data_bvp = bvp_subj.set_index('DateTime').resample(\"1S\").mean().reset_index()\n",
    "\n",
    "    # Merge all data into a single DataFrame\n",
    "    print(\"Merging data...\")\n",
    "    data_all = data_ecg_hr[['DateTime', 'HeartRate']].rename(columns={'HeartRate': 'ECG_HR_NGRs'})\n",
    "    data_all = pd.merge(data_all, data_ibi[['DateTime', 'bpm']].rename(columns={'bpm': 'E4_HR_IBI'}), on='DateTime', how='left')\n",
    "    data_all = pd.merge(data_all, data_temp[['DateTime', 'Values']].rename(columns={'Values': 'TEMP'}), on='DateTime', how='left')\n",
    "    data_all = pd.merge(data_all, data_eda[['DateTime', 'Values', 'NEW_EDA']].rename(columns={'Values': 'EDA_RAW', 'NEW_EDA': 'EDA_PHASIC'}), on='DateTime', how='left')\n",
    "    data_all = pd.merge(data_all, data_acc[['DateTime', 'AccX', 'AccY', 'AccZ']], on='DateTime', how='left')\n",
    "    data_all = pd.merge(data_all, data_bvp[['DateTime', 'Values']].rename(columns={'Values': 'BVP_Values'}), on='DateTime', how='left')\n",
    "\n",
    "    # Plot merged data\n",
    "    print(\"Plotting merged data...\")\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(data_all['DateTime'], data_all['ECG_HR_NGRs'], label='ECG HR NGRs')\n",
    "    plt.plot(data_all['DateTime'], data_all['E4_HR_IBI'], label='E4 HR IBI')\n",
    "    plt.plot(data_all['DateTime'], data_all['EDA_RAW'], label='EDA Raw')\n",
    "    plt.plot(data_all['DateTime'], data_all['TEMP'], label='Temperature')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('Merged Physiological Data')\n",
    "    plt.savefig(os.path.join(output_dir, 'merged_data.png'), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Save combined data to CSV\n",
    "    print(\"Saving combined data to CSV...\")\n",
    "    data_all.to_csv(os.path.join(output_dir, 'data_all_1Hz.csv'), index=False)\n",
    "\n",
    "    print(\"Processing complete. All figures and CSV file saved to the output directory.\")\n",
    "\n",
    "\n",
    "# Process Empatica data\n",
    "input_directory = os.path.join(path.sourcedata, 'supp', 'stress_csv', 'sub-OE009', 'ses-Lapa')\n",
    "output_directory = os.path.join(input_directory, '_1hz')\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "process_empatica_data(input_directory, output_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
