{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import *\n",
    "%matplotlib widget\n",
    "# %matplotlib inline\n",
    "# %matplotlib notebook\n",
    "datapicker = create_datapicker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Full Loop to Extract Environmental Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from pythermalcomfort.models import utci\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Initialize the Excel workbook and sheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.append([\"Participant Name\", \"Session Name\", \"Status\", \"Radiant Temperature\"])\n",
    "\n",
    "# Path information\n",
    "sourcedata = r'Z:\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\data'\n",
    "logdata    = r'Z:\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\supp\\log'\n",
    "\n",
    "# To store the mean values for each session\n",
    "all_means = []\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# FUNCTIONS\n",
    "def process_session(session_path, participant_name, session_name):\n",
    "    \n",
    "    global all_means  # Declare all_means as global\n",
    "    data_path = os.path.join(session_path)\n",
    "    try:\n",
    "        datapicker.reset(path=data_path)\n",
    "        create_dataset(datapicker=datapicker)\n",
    "        status = 1  # Success\n",
    "    except Exception as e:\n",
    "        status = 0  # Failed\n",
    "    \n",
    "    radiant_temp_status = 0  # Default to 0 if not found or if all zeros\n",
    "\n",
    "    if status == 1:\n",
    "        # Generate the sessions.tsv file\n",
    "        geodata = datapicker.geodata  # Retrieve geodata\n",
    "        create_geodata(geodata)\n",
    "\n",
    "        # Output folder\n",
    "        log_folder = os.path.join(logdata, f\"sub-{participant_name}\", f\"ses-{session_name}\")\n",
    "\n",
    "        # Get GPS coordinates, integrate them into geodata, and export to csv\n",
    "        coords = datapicker.geodata.geometry.get_coordinates(include_z=True)\n",
    "        coords.rename(columns={'y': 'latitude', 'x': 'longitude', 'z': 'elevation'}, inplace=True)\n",
    "        geodata = geodata.join(coords).drop(columns=['geometry'])\n",
    "        geodata.to_csv(os.path.join(log_folder, f\"sub-{participant_name}_ses-{session_name}_geodata.csv\"), index=False)\n",
    "\n",
    "        # Save the full geodata to an Excel file in the log directory\n",
    "        os.makedirs(log_folder, exist_ok=True)\n",
    "        geodata_file = os.path.join(log_folder, f\"sub-{participant_name}_ses-{session_name}_geodata.xlsx\")\n",
    "        geodata.to_excel(geodata_file, index=False)\n",
    "        print(f\"Geodata saved to: {geodata_file}\")\n",
    "\n",
    "        # Check if the radiant temperature column exists and contains non-zero values\n",
    "        if 'tk_thermocouple_temperature_value' in geodata:\n",
    "            if geodata['tk_thermocouple_temperature_value'].sum() != 0:\n",
    "                radiant_temp_status = 1  # Non-zero values exist\n",
    "        \n",
    "        # Log the result\n",
    "        ws.append([participant_name, session_name, status, radiant_temp_status])\n",
    "\n",
    "        # Compute the mean, median, variance, and standard deviation of the numeric columns\n",
    "        numeric_means = geodata.mean(numeric_only=True).to_dict()\n",
    "        numeric_median = geodata.median(numeric_only=True).to_dict()\n",
    "        numeric_variance = geodata.var(numeric_only=True).to_dict()\n",
    "        numeric_std = geodata.std(numeric_only=True).to_dict()\n",
    "        numeric_stats = {**numeric_means, **numeric_median, **numeric_variance, **numeric_std}\n",
    "        # Export to a CSV file\n",
    "        numeric_stats_df = pd.DataFrame(numeric_stats, index=[0])\n",
    "        numeric_stats_file = os.path.join(log_folder, f\"sub-{participant_name}_ses-{session_name}_numeric_stats.csv\")\n",
    "        numeric_stats_df.to_csv(numeric_stats_file, index=False)\n",
    "        print(f\"Numeric stats saved to: {numeric_stats_file}\")\n",
    "\n",
    "        # Append the mean values to the all_means list\n",
    "        numeric_means['participant'] = participant_name\n",
    "        numeric_means['session'] = session_name\n",
    "        all_means.append(numeric_means)\n",
    "    \n",
    "    # Log the radiant_temp_status result\n",
    "    ws.append([participant_name, session_name, status, radiant_temp_status])\n",
    "\n",
    "\n",
    "def create_geodata(geodata):\n",
    "    \"\"\"Compute UTCI across the whole time series.\"\"\"\n",
    "    \n",
    "    # Define custom parameters\n",
    "    humidity = geodata['tk_humidity_humidity_value'] / 100  # in fraction\n",
    "    wind_speed = np.sqrt(geodata['atmos_northwind_value']**2 + geodata['atmos_eastwind_value']**2)  # m/s (~2.5 m of elevation)\n",
    "    temp_atmos = geodata['atmos_airtemperature_value']  # in ºC\n",
    "    temp_tk = geodata['tk_airquality_temperature_value'] / 100  # in ºC\n",
    "    temp_tk_ptc = geodata['tk_ptc_airtemp_value'] / 100  # in ºC\n",
    "    temp_radiant = geodata['tk_thermocouple_temperature_value'] / 100  # in ºC\n",
    "\n",
    "    # Assign custom parameters to the geodata attribute\n",
    "    geodata['humidity'] = humidity\n",
    "    geodata['wind_speed'] = wind_speed\n",
    "    geodata['temp_atmos'] = temp_atmos\n",
    "    geodata['temp_tk'] = temp_tk\n",
    "    geodata['temp_tk_ptc'] = temp_tk_ptc\n",
    "    geodata['temp_radiant'] = temp_radiant\n",
    "\n",
    "    # Compute the UTCI\n",
    "    geodata['utci'] = utci(tdb=temp_atmos, tr=temp_radiant, v=wind_speed, rh=humidity)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# MAIN SCRIPT\n",
    "processed_participants = 0\n",
    "\n",
    "for participant_folder in os.listdir(sourcedata):\n",
    "    if participant_folder.startswith(\"OE\"):\n",
    "        participant_path = os.path.join(sourcedata, participant_folder)\n",
    "        for session_folder in os.listdir(participant_path):\n",
    "            session_path = os.path.join(participant_path, session_folder)\n",
    "            if os.path.isdir(session_path):\n",
    "                process_session(session_path, participant_folder, session_folder)\n",
    "\n",
    "        processed_participants += 1\n",
    "        if processed_participants >= 3:\n",
    "            break  # Stop after processing 2 participants\n",
    "\n",
    "# Save the Excel file with the updated status in the log directory\n",
    "result_file = os.path.join(logdata, \"session_processing_results.xlsx\")\n",
    "wb.save(result_file)\n",
    "\n",
    "# Save the mean values to a final CSV file\n",
    "if all_means:\n",
    "    final_means_df = pd.DataFrame(all_means)\n",
    "    final_means_file = os.path.join(logdata, \"final_means.csv\")\n",
    "    final_means_df.to_csv(final_means_file, index=False)\n",
    "    print(f\"Final CSV file with mean values saved to: {final_means_file}\")\n",
    "else:\n",
    "    print(\"No valid data found to compute mean values.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from pythermalcomfort.models import utci\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Initialize the Excel workbook and sheet for logging\n",
    "workbook = Workbook()\n",
    "worksheet = workbook.active\n",
    "worksheet.append([\"Participant ID\", \"Session ID\", \"Processing Status\", \"Radiant Temp Status\"])\n",
    "\n",
    "# Path configurations\n",
    "SOURCE_DATA_PATH = r'Z:\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\data'\n",
    "LOG_DATA_PATH = r'Z:\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\supp\\log'\n",
    "\n",
    "# List to store mean values for each session\n",
    "all_session_means = []\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# FUNCTIONS\n",
    "\n",
    "def process_session(session_dir, participant_id, session_id):\n",
    "    \"\"\"\n",
    "    Process a single session's data, compute statistics, and log results.\n",
    "    \"\"\"\n",
    "    global all_session_means  # Allow modification of the global list\n",
    "\n",
    "    # Attempt to process the dataset\n",
    "    try:\n",
    "        datapicker.reset(path=session_dir)\n",
    "        create_dataset(datapicker=datapicker)\n",
    "        processing_status = 1  # Success\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id} for participant {participant_id}: {e}\")\n",
    "        processing_status = 0  # Failed\n",
    "\n",
    "    # Default radiant temperature status\n",
    "    radiant_temp_status = 0\n",
    "\n",
    "    if processing_status == 1:\n",
    "        # Retrieve geospatial data\n",
    "        geodata = datapicker.geodata\n",
    "        compute_utci(geodata)\n",
    "\n",
    "        # Extract and rename GPS coordinates\n",
    "        coords = geodata.geometry.get_coordinates(include_z=True)\n",
    "        coords.rename(columns={'y': 'latitude', 'x': 'longitude', 'z': 'elevation'}, inplace=True)\n",
    "        geodata = geodata.join(coords).drop(columns=['geometry'])\n",
    "\n",
    "        # Export geodata to CSV\n",
    "        geodata_csv_path = os.path.join(LOG_DATA_PATH, f\"sub-{participant_id}_ses-{session_id}_geodata.csv\")\n",
    "        geodata.to_csv(geodata_csv_path, index=False)\n",
    "\n",
    "        # Save geodata to an Excel file in the participant's log directory\n",
    "        participant_log_dir = os.path.join(LOG_DATA_PATH, f\"sub-{participant_id}\", f\"ses-{session_id}\")\n",
    "        os.makedirs(participant_log_dir, exist_ok=True)\n",
    "        geodata_excel_path = os.path.join(participant_log_dir, f\"sub-{participant_id}_ses-{session_id}_geodata.xlsx\")\n",
    "        geodata.to_excel(geodata_excel_path, index=False)\n",
    "        print(f\"Geodata saved to: {geodata_excel_path}\")\n",
    "\n",
    "        # Check for radiant temperature data\n",
    "        if 'tk_thermocouple_temperature_value' in geodata.columns:\n",
    "            if geodata['tk_thermocouple_temperature_value'].sum() != 0:\n",
    "                radiant_temp_status = 1  # Radiant temperature data available\n",
    "\n",
    "        # Compute statistical metrics\n",
    "        numeric_columns = geodata.select_dtypes(include=[np.number])\n",
    "        stats = {\n",
    "            'mean': numeric_columns.mean().to_dict(),\n",
    "            'median': numeric_columns.median().to_dict(),\n",
    "            'variance': numeric_columns.var().to_dict(),\n",
    "            'std_dev': numeric_columns.std().to_dict()\n",
    "        }\n",
    "\n",
    "        # Export statistics to CSV\n",
    "        stats_df = pd.DataFrame(stats)\n",
    "        stats_csv_path = os.path.join(participant_log_dir, f\"sub-{participant_id}_ses-{session_id}_stats.csv\")\n",
    "        stats_df.to_csv(stats_csv_path, index=False)\n",
    "        print(f\"Statistical data saved to: {stats_csv_path}\")\n",
    "\n",
    "        # Append mean values to the global list\n",
    "        session_means = stats['mean']\n",
    "        session_means['participant_id'] = participant_id\n",
    "        session_means['session_id'] = session_id\n",
    "        all_session_means.append(session_means)\n",
    "\n",
    "    # Log the processing results\n",
    "    worksheet.append([participant_id, session_id, processing_status, radiant_temp_status])\n",
    "\n",
    "def compute_utci(geodata):\n",
    "    \"\"\"\n",
    "    Compute the Universal Thermal Climate Index (UTCI) for the given geodata.\n",
    "    \"\"\"\n",
    "    # Calculate custom parameters\n",
    "    geodata['humidity'] = geodata['tk_humidity_humidity_value'] / 100  # Convert to fraction\n",
    "    geodata['wind_speed'] = np.sqrt(\n",
    "        geodata['atmos_northwind_value']**2 + geodata['atmos_eastwind_value']**2\n",
    "    )  # Wind speed in m/s\n",
    "    geodata['temp_atmos'] = geodata['atmos_airtemperature_value']  # Atmospheric temperature in °C\n",
    "    geodata['temp_tk'] = geodata['tk_airquality_temperature_value'] / 100  # TK temperature in °C\n",
    "    geodata['temp_tk_ptc'] = geodata['tk_ptc_airtemp_value'] / 100  # PTC air temperature in °C\n",
    "    geodata['temp_radiant'] = geodata['tk_thermocouple_temperature_value'] / 100  # Radiant temperature in °C\n",
    "\n",
    "    # Compute UTCI\n",
    "    geodata['utci'] = utci(\n",
    "        tdb=geodata['temp_atmos'],\n",
    "        tr=geodata['temp_radiant'],\n",
    "        v=geodata['wind_speed'],\n",
    "        rh=geodata['humidity'] * 100  # Convert back to percentage\n",
    "    )\n",
    "\n",
    "def get_session_id(session_dir):\n",
    "    \"\"\"\n",
    "    Retrieve the session ID from a metadata file or other means.\n",
    "    If not available, return the session directory name.\n",
    "    \"\"\"\n",
    "    # Placeholder for session ID retrieval logic\n",
    "    # For example, read from a 'session_info.txt' file inside the session directory\n",
    "    session_info_path = os.path.join(session_dir, 'session_info.txt')\n",
    "    if os.path.exists(session_info_path):\n",
    "        with open(session_info_path, 'r') as file:\n",
    "            session_id = file.read().strip()\n",
    "            return session_id\n",
    "    else:\n",
    "        # If no metadata file, use the directory name as session ID\n",
    "        return os.path.basename(session_dir)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# MAIN SCRIPT\n",
    "\n",
    "def main():\n",
    "    max_participants_to_process = 3\n",
    "    participants_processed = 0\n",
    "\n",
    "    for participant_folder in os.listdir(SOURCE_DATA_PATH):\n",
    "        if participant_folder.startswith(\"OE\"):\n",
    "            participant_id = participant_folder  # Use the folder name as participant ID\n",
    "            participant_path = os.path.join(SOURCE_DATA_PATH, participant_folder)\n",
    "\n",
    "            for session_folder in os.listdir(participant_path):\n",
    "                session_dir = os.path.join(participant_path, session_folder)\n",
    "                if os.path.isdir(session_dir):\n",
    "                    # Retrieve the actual session ID\n",
    "                    session_id = get_session_id(session_dir)\n",
    "                    process_session(session_dir, participant_id, session_id)\n",
    "\n",
    "            participants_processed += 1\n",
    "            if participants_processed >= max_participants_to_process:\n",
    "                break  # Stop processing after the specified number of participants\n",
    "\n",
    "    # Save the Excel log\n",
    "    excel_log_path = os.path.join(LOG_DATA_PATH, \"session_processing_results.xlsx\")\n",
    "    workbook.save(excel_log_path)\n",
    "    print(f\"Processing log saved to: {excel_log_path}\")\n",
    "\n",
    "    # Save the mean values to a final CSV file\n",
    "    if all_session_means:\n",
    "        final_means_df = pd.DataFrame(all_session_means)\n",
    "        final_means_csv_path = os.path.join(LOG_DATA_PATH, \"final_session_means.csv\")\n",
    "        final_means_df.to_csv(final_means_csv_path, index=False)\n",
    "        print(f\"Final CSV file with mean values saved to: {final_means_csv_path}\")\n",
    "    else:\n",
    "        print(\"No valid data found to compute mean values.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from pythermalcomfort.models import utci\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Initialize the Excel workbook and sheet for logging\n",
    "workbook = Workbook()\n",
    "worksheet = workbook.active\n",
    "worksheet.append([\"Participant ID\", \"Session ID\", \"Processing Status\", \"Radiant Temp Status\"])\n",
    "\n",
    "# Path configurations\n",
    "SOURCE_DATA_PATH = r'Z:\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\data'\n",
    "LOG_DATA_PATH = r'Z:\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\supp\\log'\n",
    "\n",
    "# List to store mean values for each session\n",
    "all_session_means = []\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# FUNCTIONS\n",
    "\n",
    "def process_session(session_dir, participant_id, session_id):\n",
    "    \"\"\"\n",
    "    Process a single session's data, compute statistics, and log results.\n",
    "    \"\"\"\n",
    "    global all_session_means  # Allow modification of the global list\n",
    "\n",
    "    # Attempt to process the dataset\n",
    "    try:\n",
    "        # Assume datapicker and create_dataset are defined elsewhere\n",
    "        datapicker.reset(path=session_dir)\n",
    "        create_dataset(datapicker=datapicker)\n",
    "        processing_status = 1  # Success\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id} for participant {participant_id}: {e}\")\n",
    "        processing_status = 0  # Failed\n",
    "\n",
    "    # Default radiant temperature status\n",
    "    radiant_temp_status = 0\n",
    "\n",
    "    if processing_status == 1:\n",
    "        # Retrieve geospatial data\n",
    "        geodata = datapicker.geodata\n",
    "        compute_utci(geodata)\n",
    "\n",
    "        # Extract and rename GPS coordinates\n",
    "        coords = geodata.geometry.get_coordinates(include_z=True)\n",
    "        coords.rename(columns={'y': 'latitude', 'x': 'longitude', 'z': 'elevation'}, inplace=True)\n",
    "        geodata = geodata.join(coords).drop(columns=['geometry'])\n",
    "\n",
    "        # Define paths for saving files\n",
    "        participant_log_dir = os.path.join(LOG_DATA_PATH, f\"sub-{participant_id}\", f\"ses-{session_id}\")\n",
    "        os.makedirs(participant_log_dir, exist_ok=True)\n",
    "        geodata_csv_path = os.path.join(participant_log_dir, f\"sub-{participant_id}_ses-{session_id}_geodata.csv\")\n",
    "        geodata_excel_path = os.path.join(participant_log_dir, f\"sub-{participant_id}_ses-{session_id}_geodata.xlsx\")\n",
    "        stats_csv_path = os.path.join(participant_log_dir, f\"sub-{participant_id}_ses-{session_id}_stats.csv\")\n",
    "\n",
    "        # Save geodata to CSV with exception handling\n",
    "        try:\n",
    "            geodata.to_csv(geodata_csv_path, index=False)\n",
    "            print(f\"Geodata CSV saved to: {geodata_csv_path}\")\n",
    "        except PermissionError as e:\n",
    "            print(f\"PermissionError when saving geodata CSV to {geodata_csv_path}: {e}\")\n",
    "            geodata_csv_path = f\"sub-{participant_id}_ses-{session_id}_geodata.csv\"\n",
    "            geodata.to_csv(geodata_csv_path, index=False)\n",
    "            print(f\"Geodata CSV saved to current directory as: {geodata_csv_path}\")\n",
    "\n",
    "        # Save geodata to Excel with exception handling\n",
    "        try:\n",
    "            geodata.to_excel(geodata_excel_path, index=False)\n",
    "            print(f\"Geodata Excel saved to: {geodata_excel_path}\")\n",
    "        except PermissionError as e:\n",
    "            print(f\"PermissionError when saving geodata Excel to {geodata_excel_path}: {e}\")\n",
    "            geodata_excel_path = f\"sub-{participant_id}_ses-{session_id}_geodata.xlsx\"\n",
    "            geodata.to_excel(geodata_excel_path, index=False)\n",
    "            print(f\"Geodata Excel saved to current directory as: {geodata_excel_path}\")\n",
    "\n",
    "        # Check for radiant temperature data\n",
    "        if 'tk_thermocouple_temperature_value' in geodata.columns:\n",
    "            if geodata['tk_thermocouple_temperature_value'].sum() != 0:\n",
    "                radiant_temp_status = 1  # Radiant temperature data available\n",
    "\n",
    "        # Compute statistical metrics\n",
    "        numeric_columns = geodata.select_dtypes(include=[np.number])\n",
    "        stats = {\n",
    "            'mean': numeric_columns.mean().to_dict(),\n",
    "            'median': numeric_columns.median().to_dict(),\n",
    "            'variance': numeric_columns.var().to_dict(),\n",
    "            'std_dev': numeric_columns.std().to_dict()\n",
    "        }\n",
    "\n",
    "        # Save statistics to CSV with exception handling\n",
    "        stats_df = pd.DataFrame(stats)\n",
    "        try:\n",
    "            stats_df.to_csv(stats_csv_path, index=False)\n",
    "            print(f\"Statistical data saved to: {stats_csv_path}\")\n",
    "        except PermissionError as e:\n",
    "            print(f\"PermissionError when saving stats CSV to {stats_csv_path}: {e}\")\n",
    "            stats_csv_path = f\"sub-{participant_id}_ses-{session_id}_stats.csv\"\n",
    "            stats_df.to_csv(stats_csv_path, index=False)\n",
    "            print(f\"Statistical data saved to current directory as: {stats_csv_path}\")\n",
    "\n",
    "        # Append mean values to the global list\n",
    "        session_means = stats['mean']\n",
    "        session_means['participant_id'] = participant_id\n",
    "        session_means['session_id'] = session_id\n",
    "        all_session_means.append(session_means)\n",
    "\n",
    "    # Log the processing results\n",
    "    worksheet.append([participant_id, session_id, processing_status, radiant_temp_status])\n",
    "\n",
    "def compute_utci(geodata):\n",
    "    \"\"\"\n",
    "    Compute the Universal Thermal Climate Index (UTCI) for the given geodata.\n",
    "    \"\"\"\n",
    "    # Calculate custom parameters\n",
    "    geodata['humidity'] = geodata['tk_humidity_humidity_value'] / 100  # Convert to fraction\n",
    "    geodata['wind_speed'] = np.sqrt(\n",
    "        geodata['atmos_northwind_value']**2 + geodata['atmos_eastwind_value']**2\n",
    "    )  # Wind speed in m/s\n",
    "    geodata['temp_atmos'] = geodata['atmos_airtemperature_value']  # Atmospheric temperature in °C\n",
    "    geodata['temp_tk'] = geodata['tk_airquality_temperature_value'] / 100  # TK temperature in °C\n",
    "    geodata['temp_tk_ptc'] = geodata['tk_ptc_airtemp_value'] / 100  # PTC air temperature in °C\n",
    "    geodata['temp_radiant'] = geodata['tk_thermocouple_temperature_value'] / 100  # Radiant temperature in °C\n",
    "\n",
    "    # Compute UTCI\n",
    "    geodata['utci'] = utci(\n",
    "        tdb=geodata['temp_atmos'],\n",
    "        tr=geodata['temp_radiant'],\n",
    "        v=geodata['wind_speed'],\n",
    "        rh=geodata['humidity'] * 100  # Convert back to percentage\n",
    "    )\n",
    "\n",
    "def get_session_id(session_dir):\n",
    "    \"\"\"\n",
    "    Retrieve the session ID from a metadata file or other means.\n",
    "    If not available, return the session directory name.\n",
    "    \"\"\"\n",
    "    # Placeholder for session ID retrieval logic\n",
    "    # For example, read from a 'session_info.txt' file inside the session directory\n",
    "    session_info_path = os.path.join(session_dir, 'session_info.txt')\n",
    "    if os.path.exists(session_info_path):\n",
    "        with open(session_info_path, 'r') as file:\n",
    "            session_id = file.read().strip()\n",
    "            return session_id\n",
    "    else:\n",
    "        # If no metadata file, use the directory name as session ID\n",
    "        return os.path.basename(session_dir)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# MAIN SCRIPT\n",
    "\n",
    "def main():\n",
    "    max_participants_to_process = 3\n",
    "    participants_processed = 0\n",
    "\n",
    "    for participant_folder in os.listdir(SOURCE_DATA_PATH):\n",
    "        if participant_folder.startswith(\"OE\"):\n",
    "            participant_id = participant_folder  # Use the folder name as participant ID\n",
    "            participant_path = os.path.join(SOURCE_DATA_PATH, participant_folder)\n",
    "\n",
    "            for session_folder in os.listdir(participant_path):\n",
    "                session_dir = os.path.join(participant_path, session_folder)\n",
    "                if os.path.isdir(session_dir):\n",
    "                    # Retrieve the actual session ID\n",
    "                    session_id = get_session_id(session_dir)\n",
    "                    process_session(session_dir, participant_id, session_id)\n",
    "\n",
    "            participants_processed += 1\n",
    "            if participants_processed >= max_participants_to_process:\n",
    "                break  # Stop processing after the specified number of participants\n",
    "\n",
    "    # Save the Excel log with exception handling\n",
    "    try:\n",
    "        excel_log_path = os.path.join(LOG_DATA_PATH, \"session_processing_results.xlsx\")\n",
    "        workbook.save(excel_log_path)\n",
    "        print(f\"Processing log saved to: {excel_log_path}\")\n",
    "    except PermissionError as e:\n",
    "        print(f\"PermissionError when saving the Excel log to {excel_log_path}: {e}\")\n",
    "        excel_log_path = \"session_processing_results.xlsx\"\n",
    "        workbook.save(excel_log_path)\n",
    "        print(f\"Processing log saved to current directory as: {excel_log_path}\")\n",
    "\n",
    "    # Save the mean values to a final CSV file with exception handling\n",
    "    if all_session_means:\n",
    "        final_means_df = pd.DataFrame(all_session_means)\n",
    "        try:\n",
    "            final_means_csv_path = os.path.join(LOG_DATA_PATH, \"final_session_means.csv\")\n",
    "            final_means_df.to_csv(final_means_csv_path, index=False)\n",
    "            print(f\"Final CSV file with mean values saved to: {final_means_csv_path}\")\n",
    "        except PermissionError as e:\n",
    "            print(f\"PermissionError when saving final means CSV to {final_means_csv_path}: {e}\")\n",
    "            final_means_csv_path = \"final_session_means.csv\"\n",
    "            final_means_df.to_csv(final_means_csv_path, index=False)\n",
    "            print(f\"Final CSV file with mean values saved to current directory as: {final_means_csv_path}\")\n",
    "    else:\n",
    "        print(\"No valid data found to compute mean values.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claude code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import Workbook\n",
    "from pythermalcomfort.models import utci\n",
    "\n",
    "# Path information\n",
    "sourcedata = r'Z:\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\data'\n",
    "logdata    = r'Z:\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\supp\\log'\n",
    "\n",
    "# To store the statistics for all sessions\n",
    "all_stats = []\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# FUNCTIONS\n",
    "def process_session(session_path, participant_name, session_name):\n",
    "    global all_stats\n",
    "    data_path = os.path.join(session_path)\n",
    "    try:\n",
    "        datapicker.reset(path=data_path)\n",
    "        create_dataset(datapicker=datapicker)\n",
    "        status = 1  # Success\n",
    "    except Exception as e:\n",
    "        status = 0  # Failed\n",
    "        return\n",
    "\n",
    "    if status == 1:\n",
    "        # Generate the sessions.tsv file\n",
    "        geodata = datapicker.geodata  # Retrieve geodata\n",
    "        create_geodata(geodata)\n",
    "\n",
    "        # Output folder\n",
    "        log_folder = os.path.join(logdata, f\"sub-{participant_name}\", f\"ses-{session_name}\")\n",
    "        os.makedirs(log_folder, exist_ok=True)\n",
    "\n",
    "        # Compute statistics for numeric columns\n",
    "        numeric_data = geodata.select_dtypes(include=[np.number])\n",
    "        stats = {\n",
    "            'mean': numeric_data.mean(),\n",
    "            'median': numeric_data.median(),\n",
    "            'variance': numeric_data.var(),\n",
    "            'std': numeric_data.std()\n",
    "        }\n",
    "        \n",
    "        # Add participant and session information\n",
    "        for stat_name, stat_values in stats.items():\n",
    "            stat_values['participant'] = participant_name\n",
    "            stat_values['session'] = session_name\n",
    "            all_stats.append(pd.DataFrame(stat_values).T)\n",
    "\n",
    "# The create_geodata function remains unchanged\n",
    "def create_geodata(geodata):\n",
    "    \"\"\"Compute UTCI across the whole time series.\"\"\"\n",
    "    \n",
    "    # Define custom parameters\n",
    "    humidity = geodata['tk_humidity_humidity_value'] / 100  # in fraction\n",
    "    wind_speed = np.sqrt(geodata['atmos_northwind_value']**2 + geodata['atmos_eastwind_value']**2)  # m/s (~2.5 m of elevation)\n",
    "    temp_atmos = geodata['atmos_airtemperature_value']  # in ºC\n",
    "    temp_tk = geodata['tk_airquality_temperature_value'] / 100  # in ºC\n",
    "    temp_tk_ptc = geodata['tk_ptc_airtemp_value'] / 100  # in ºC\n",
    "    temp_radiant = geodata['tk_thermocouple_temperature_value'] / 100  # in ºC\n",
    "\n",
    "    # Assign custom parameters to the geodata attribute\n",
    "    geodata['humidity'] = humidity\n",
    "    geodata['wind_speed'] = wind_speed\n",
    "    geodata['temp_atmos'] = temp_atmos\n",
    "    geodata['temp_tk'] = temp_tk\n",
    "    geodata['temp_tk_ptc'] = temp_tk_ptc\n",
    "    geodata['temp_radiant'] = temp_radiant\n",
    "\n",
    "    # Compute the UTCI\n",
    "    geodata['utci'] = utci(tdb=temp_atmos, tr=temp_radiant, v=wind_speed, rh=humidity)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# MAIN SCRIPT\n",
    "processed_participants = 0\n",
    "\n",
    "for participant_folder in os.listdir(sourcedata):\n",
    "    if participant_folder.startswith(\"OE\"):\n",
    "        participant_path = os.path.join(sourcedata, participant_folder)\n",
    "        for session_folder in os.listdir(participant_path):\n",
    "            session_path = os.path.join(participant_path, session_folder)\n",
    "            if os.path.isdir(session_path):\n",
    "                process_session(session_path, participant_folder, session_folder)\n",
    "\n",
    "        processed_participants += 1\n",
    "        if processed_participants >= 2:\n",
    "            break  # Stop after processing 2 participants\n",
    "\n",
    "# Combine all statistics\n",
    "if all_stats:\n",
    "    final_stats_df = pd.concat(all_stats, ignore_index=True)\n",
    "    \n",
    "    # Compute overall statistics\n",
    "    overall_stats = pd.DataFrame({\n",
    "        'mean': final_stats_df.mean(),\n",
    "        'median': final_stats_df.median(),\n",
    "        'variance': final_stats_df.var(),\n",
    "        'std': final_stats_df.std()\n",
    "    }).T\n",
    "    \n",
    "    # Remove 'participant' and 'session' columns from overall statistics\n",
    "    overall_stats = overall_stats.drop(columns=['participant', 'session'])\n",
    "    \n",
    "    # Save the overall statistics to an Excel file\n",
    "    final_stats_file = os.path.join(logdata, \"overall_statistics.xlsx\")\n",
    "    overall_stats.to_excel(final_stats_file)\n",
    "    print(f\"Overall statistics saved to: {final_stats_file}\")\n",
    "else:\n",
    "    print(\"No valid data found to compute statistics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joaop\\Anaconda3\\envs\\emotional-cities\\Lib\\site-packages\\pluma\\io\\harp.py:44: UserWarning: Harp stream file            @(WIN) --> \\\\nas-emotional.fm.ul.pt\\eMotional\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\data\\OE003\\Lisbon_Estrela_sub-OE119003_2024-10-04T141631Z\\Streams_227 could not be found.\n",
      "  warnings.warn(f'Harp stream file\\\n",
      "c:\\Users\\joaop\\Anaconda3\\envs\\emotional-cities\\Lib\\site-packages\\pluma\\io\\harp.py:44: UserWarning: Harp stream file            @(WIN) --> \\\\nas-emotional.fm.ul.pt\\eMotional\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\data\\OE003\\Lisbon_Estrela_sub-OE119003_2024-10-04T141631Z\\Streams_228 could not be found.\n",
      "  warnings.warn(f'Harp stream file\\\n",
      "c:\\Users\\joaop\\Anaconda3\\envs\\emotional-cities\\Lib\\site-packages\\pluma\\io\\harp.py:44: UserWarning: Harp stream file            @(WIN) --> \\\\nas-emotional.fm.ul.pt\\eMotional\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\data\\OE003\\Lisbon_Estrela_sub-OE119003_2024-10-04T141631Z\\Streams_229 could not be found.\n",
      "  warnings.warn(f'Harp stream file\\\n",
      "c:\\Users\\joaop\\Anaconda3\\envs\\emotional-cities\\Lib\\site-packages\\pluma\\io\\harp.py:44: UserWarning: Harp stream file            @(WIN) --> \\\\nas-emotional.fm.ul.pt\\eMotional\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\data\\OE003\\Lisbon_Estrela_sub-OE119003_2024-10-04T141631Z\\Streams_232 could not be found.\n",
      "  warnings.warn(f'Harp stream file\\\n",
      "c:\\Users\\joaop\\Anaconda3\\envs\\emotional-cities\\Lib\\site-packages\\pluma\\io\\empatica.py:55: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  stream_id = empatica_stream['Message'][0].split(' ')[0]\n",
      "c:\\Users\\joaop\\Anaconda3\\envs\\emotional-cities\\Lib\\site-packages\\pluma\\io\\empatica.py:55: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  stream_id = empatica_stream['Message'][0].split(' ')[0]\n",
      "c:\\Users\\joaop\\Anaconda3\\envs\\emotional-cities\\Lib\\site-packages\\pluma\\io\\empatica.py:55: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  stream_id = empatica_stream['Message'][0].split(' ')[0]\n",
      "c:\\Users\\joaop\\Anaconda3\\envs\\emotional-cities\\Lib\\site-packages\\pluma\\io\\empatica.py:55: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  stream_id = empatica_stream['Message'][0].split(' ')[0]\n",
      "c:\\Users\\joaop\\Anaconda3\\envs\\emotional-cities\\Lib\\site-packages\\pluma\\io\\empatica.py:55: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  stream_id = empatica_stream['Message'][0].split(' ')[0]\n",
      "c:\\Users\\joaop\\Anaconda3\\envs\\emotional-cities\\Lib\\site-packages\\pluma\\io\\empatica.py:55: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  stream_id = empatica_stream['Message'][0].split(' ')[0]\n",
      "c:\\Users\\joaop\\Anaconda3\\envs\\emotional-cities\\Lib\\site-packages\\pluma\\io\\empatica.py:55: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  stream_id = empatica_stream['Message'][0].split(' ')[0]\n",
      "c:\\Users\\joaop\\Anaconda3\\envs\\emotional-cities\\Lib\\site-packages\\pluma\\io\\empatica.py:55: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  stream_id = empatica_stream['Message'][0].split(' ')[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@(WIN) --> \\\\nas-emotional.fm.ul.pt\\eMotional\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\data\\OE003\\Lisbon_Estrela_sub-OE119003_2024-10-04T141631Z\\20241004151624_OE119003_EXP4.nedf\n",
      "Reading file...\n",
      "Header information has been correctly retrieved.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Z:\\\\Exp_4-outdoor_walk\\\\lisbon\\\\sourcedata\\\\supp\\\\log\\\\session_processing_results.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 109\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Save the Excel file with the updated status in the log directory\u001b[39;00m\n\u001b[0;32m    108\u001b[0m result_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(logdata, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession_processing_results.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 109\u001b[0m wb\u001b[38;5;241m.\u001b[39msave(result_file)\n",
      "File \u001b[1;32mc:\\Users\\joaop\\Anaconda3\\envs\\emotional-cities\\Lib\\site-packages\\openpyxl\\workbook\\workbook.py:386\u001b[0m, in \u001b[0;36mWorkbook.save\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworksheets:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_sheet()\n\u001b[1;32m--> 386\u001b[0m save_workbook(\u001b[38;5;28mself\u001b[39m, filename)\n",
      "File \u001b[1;32mc:\\Users\\joaop\\Anaconda3\\envs\\emotional-cities\\Lib\\site-packages\\openpyxl\\writer\\excel.py:291\u001b[0m, in \u001b[0;36msave_workbook\u001b[1;34m(workbook, filename)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_workbook\u001b[39m(workbook, filename):\n\u001b[0;32m    280\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save the given workbook on the filesystem under the name filename.\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m    :param workbook: the workbook to save\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    289\u001b[0m \n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     archive \u001b[38;5;241m=\u001b[39m ZipFile(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, ZIP_DEFLATED, allowZip64\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    292\u001b[0m     workbook\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39mmodified \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow(tz\u001b[38;5;241m=\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mtimezone\u001b[38;5;241m.\u001b[39mutc)\u001b[38;5;241m.\u001b[39mreplace(tzinfo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    293\u001b[0m     writer \u001b[38;5;241m=\u001b[39m ExcelWriter(workbook, archive)\n",
      "File \u001b[1;32mc:\\Users\\joaop\\Anaconda3\\envs\\emotional-cities\\Lib\\zipfile\\__init__.py:1331\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1331\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mopen(file, filemode)\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   1333\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Z:\\\\Exp_4-outdoor_walk\\\\lisbon\\\\sourcedata\\\\supp\\\\log\\\\session_processing_results.xlsx'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from pythermalcomfort.models import utci\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Initialize the Excel workbook and sheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.append([\"Participant Name\", \"Session Name\", \"Status\", \"Radiant Temperature\"])\n",
    "\n",
    "# Path information\n",
    "sourcedata = r'Z:\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\data'\n",
    "logdata    = r'Z:\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\supp\\log'\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# FUNCTIONS\n",
    "def process_session(session_path, participant_name, session_name):\n",
    "    \n",
    "    data_path = os.path.join(session_path)\n",
    "    try:\n",
    "        datapicker.reset(path=data_path)\n",
    "        create_dataset(datapicker=datapicker)\n",
    "        status = 1  # Success\n",
    "    except Exception as e:\n",
    "        status = 0  # Failed\n",
    "    \n",
    "    radiant_temp_status = 0  # Default to 0 if not found or if all zeros\n",
    "\n",
    "    if status == 1:\n",
    "        # Generate the sessions.tsv file\n",
    "        geodata = datapicker.geodata  # Retrieve geodata\n",
    "        create_geodata(geodata)\n",
    "\n",
    "        # Output folder\n",
    "        log_folder = os.path.join(logdata, f\"sub-{participant_name}\", f\"ses-{session_name}\")\n",
    "        os.makedirs(log_folder, exist_ok=True)\n",
    "\n",
    "        # Check if the radiant temperature column exists and contains non-zero values\n",
    "        if 'tk_thermocouple_temperature_value' in geodata:\n",
    "            if geodata['tk_thermocouple_temperature_value'].sum() != 0:\n",
    "                radiant_temp_status = 1  # Non-zero values exist\n",
    "        \n",
    "        # Log the result\n",
    "        ws.append([participant_name, session_name, status, radiant_temp_status])\n",
    "\n",
    "        # Compute the mean, median, variance, and standard deviation of the numeric columns\n",
    "        numeric_cols = geodata.select_dtypes(include=np.number)\n",
    "\n",
    "        numeric_stats = pd.DataFrame({\n",
    "            'Mean': numeric_cols.mean(),\n",
    "            'Median': numeric_cols.median(),\n",
    "            'Variance': numeric_cols.var(),\n",
    "            'Std Dev': numeric_cols.std()\n",
    "        })\n",
    "\n",
    "        # Re-arrange the DataFrame so that rows are statistics and columns are variables\n",
    "        numeric_stats = numeric_stats.T\n",
    "\n",
    "        # Save the numeric statistics to an Excel file\n",
    "        numeric_stats_file = os.path.join(log_folder, f\"sub-{participant_name}_ses-{session_name}_numeric_stats.xlsx\")\n",
    "        numeric_stats.to_excel(numeric_stats_file, index=True)\n",
    "        print(f\"Numeric stats saved to: {numeric_stats_file}\")\n",
    "\n",
    "        # Log the radiant_temp_status result\n",
    "        ws.append([participant_name, session_name, status, radiant_temp_status])\n",
    "\n",
    "def create_geodata(geodata):\n",
    "    \"\"\"Compute UTCI across the whole time series.\"\"\"\n",
    "    \n",
    "    # Define custom parameters\n",
    "    humidity = geodata['tk_humidity_humidity_value'] / 100  # in fraction\n",
    "    wind_speed = np.sqrt(geodata['atmos_northwind_value']**2 + geodata['atmos_eastwind_value']**2)  # m/s (~2.5 m of elevation)\n",
    "    temp_atmos = geodata['atmos_airtemperature_value']  # in ºC\n",
    "    temp_tk = geodata['tk_airquality_temperature_value'] / 100  # in ºC\n",
    "    temp_tk_ptc = geodata['tk_ptc_airtemp_value'] / 100  # in ºC\n",
    "    temp_radiant = geodata['tk_thermocouple_temperature_value'] / 100  # in ºC\n",
    "\n",
    "    # Assign custom parameters to the geodata attribute\n",
    "    geodata['humidity'] = humidity\n",
    "    geodata['wind_speed'] = wind_speed\n",
    "    geodata['temp_atmos'] = temp_atmos\n",
    "    geodata['temp_tk'] = temp_tk\n",
    "    geodata['temp_tk_ptc'] = temp_tk_ptc\n",
    "    geodata['temp_radiant'] = temp_radiant\n",
    "\n",
    "    # Compute the UTCI\n",
    "    geodata['utci'] = utci(tdb=temp_atmos, tr=temp_radiant, v=wind_speed, rh=humidity)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# MAIN SCRIPT\n",
    "processed_participants = 0\n",
    "\n",
    "for participant_folder in os.listdir(sourcedata):\n",
    "    if participant_folder.startswith(\"OE\"):\n",
    "        participant_path = os.path.join(sourcedata, participant_folder)\n",
    "        for session_folder in os.listdir(participant_path):\n",
    "            session_path = os.path.join(participant_path, session_folder)\n",
    "            if os.path.isdir(session_path):\n",
    "                process_session(session_path, participant_folder, session_folder)\n",
    "\n",
    "        processed_participants += 1\n",
    "        if processed_participants >= 3:\n",
    "            break  # Stop after processing 3 participants\n",
    "\n",
    "# Save the Excel file with the updated status in the log directory\n",
    "result_file = os.path.join(logdata, \"session_processing_results.xlsx\")\n",
    "wb.save(result_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotional-cities",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
