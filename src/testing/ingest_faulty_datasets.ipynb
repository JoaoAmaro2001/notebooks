{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'modules'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmissing_sync\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_schema\n\u001b[0;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidget\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'modules'"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from modules import *\n",
    "from missing_sync import build_schema\n",
    "%matplotlib widget\n",
    "datapicker = create_datapicker(path=r'Z:\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\data\\OE001',schema=build_schema, calibrate_ubx_to_harp=False)\n",
    "display(datapicker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(for_climate)\n",
    "\n",
    "for path in participants_info:\n",
    "    try:        \n",
    "        # Load the dataset\n",
    "        data_path  = path['session_folder']\n",
    "        datapicker = create_datapicker(path=data_path,schema=build_schema, calibrate_ubx_to_harp=False)\n",
    "        dataset    = load_dataset(datapicker.selected_path, ubx=True, unity=False, calibrate_ubx_to_harp=False, schema=build_schema)\n",
    "\n",
    "        # Create geodata\n",
    "        geodata = dataset.to_geoframe()\n",
    "\n",
    "        # Process geodata\n",
    "        geodata['time'] = geodata.index.to_pydatetime()\n",
    "        geodata         = tidy_geodata(geodata)\n",
    "        geodata         = add_environmental_metrics(geodata)\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred for participant code '{path['participant_code']}': {e}\")\n",
    "        print(\"Most likely needs to have an updated EEG .nedf file\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load dataset without GPS (para Andre: está a dar erro no load)\n",
    "\n",
    "datasets without GPS (13 in total):\n",
    "OE101001\n",
    "OE101002\n",
    "OE102002\n",
    "OE102003\n",
    "OE104003\n",
    "OE104004\n",
    "OE101012\n",
    "OE106005\n",
    "OE106011\n",
    "OE106010\n",
    "OE106016\n",
    "OE106021\n",
    "OE106032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(datapicker.selected_path, ubx=True, unity=False, calibrate_ubx_to_harp=False, schema=build_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapicker.geodata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploremap(datapicker.geodata, column='tk_airquality_iaqindex_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapicker = create_datapicker(path=r'Z:\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\data\\OE003', schema=build_schema)\n",
    "display(datapicker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import *\n",
    "from pluma.schema.outdoor import build_schema\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapicker = create_datapicker(path=r'Z:\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\data\\OE003', schema=build_schema)\n",
    "display(datapicker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Explore Dataset Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploremap(datapicker.geodata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Explore Dataset Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datapicker.dataset.streams.EEG.data)\n",
    "\n",
    "datapicker.dataset.streams.EEG.data[\"np_time\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapicker.dataset.streams.EEG.data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traces({\n",
    "    'accelX': datapicker.dataset.streams.Accelerometer.data[\"Accl_X\"],\n",
    "    'temp (C)': datapicker.dataset.streams.TK.AirQuality.Temperature.data/100,\n",
    "    'angleX': datapicker.dataset.streams.Accelerometer.data[\"Orientation_X\"],\n",
    "    'altitude': datapicker.dataset.georeference.elevation,\n",
    "    'iaq': datapicker.dataset.streams.TK.AirQuality.IAQIndex.data,\n",
    "    'eeg': datapicker.dataset.streams.EEG.data.np_eeg,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to IGOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from pythermalcomfort.models import utci\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Initialize the Excel workbook and sheet\n",
    "\n",
    "\n",
    "# Path information\n",
    "#logdata    = r'Z:\\Exp_4-outdoor_walk\\lisbon\\sourcedata\\supp\\log'\n",
    "\n",
    "# To store the mean values for each session\n",
    "# all_means = []\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# FUNCTIONS\n",
    "\n",
    "radiant_temp_status = 0  # Default to 0 if not found or if all zeros\n",
    "\n",
    "# Generate the sessions.tsv file\n",
    "geodata = datapicker.geodata  # Retrieve geodata\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define custom parameters\n",
    "humidity = geodata['tk_humidity_humidity_value'] / 100  # in fraction\n",
    "wind_speed = np.sqrt(geodata['atmos_northwind_value']**2 + geodata['atmos_eastwind_value']**2)  # m/s (~2.5 m of elevation)\n",
    "temp_atmos = geodata['atmos_airtemperature_value']  # in ºC\n",
    "temp_tk = geodata['tk_airquality_temperature_value'] / 100  # in ºC\n",
    "temp_tk_ptc = geodata['tk_ptc_airtemp_value'] / 100  # in ºC\n",
    "temp_radiant = geodata['tk_thermocouple_temperature_value'] / 100  # in ºC\n",
    "\n",
    "# Assign custom parameters to the geodata attribute\n",
    "geodata['humidity'] = humidity\n",
    "geodata['wind_speed'] = wind_speed\n",
    "geodata['temp_atmos'] = temp_atmos\n",
    "geodata['temp_tk'] = temp_tk\n",
    "geodata['temp_tk_ptc'] = temp_tk_ptc\n",
    "geodata['temp_radiant'] = temp_radiant\n",
    "\n",
    "# Compute the UTCI\n",
    "geodata['utci'] = utci(tdb=temp_atmos, tr=temp_radiant, v=wind_speed, rh=humidity)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get GPS coordinates and integrate them into geodata\n",
    "coords = datapicker.geodata.geometry.get_coordinates(include_z=True)\n",
    "coords.rename(columns={'y': 'latitude', 'x': 'longitude', 'z': 'elevation'}, inplace=True)\n",
    "geodata = geodata.join(coords).drop(columns=['geometry'])\n",
    "\n",
    "# Check if the radiant temperature column exists and contains non-zero values\n",
    "if 'tk_thermocouple_temperature_value' in geodata:\n",
    "    if geodata['tk_thermocouple_temperature_value'].sum() != 0:\n",
    "        radiant_temp_status = 1  # Non-zero values exist\n",
    "\n",
    "# Save the full geodata to an Excel file in the log directory\n",
    "#log_folder = os.path.join(logdata, f\"sub-{participant_name}\", f\"ses-{session_name}\")\n",
    "#os.makedirs(log_folder, exist_ok=True)\n",
    "# geodata_file = os.path.join(log_folder, f\"sub-{participant_name}_ses-{session_name}_geodata.xlsx\")\n",
    "# geodata.to_excel(geodata_file, index=False)\n",
    "\n",
    "# Compute the mean of all numerical columns\n",
    "# numeric_means = geodata.mean(numeric_only=True).to_dict()\n",
    "# numeric_means['Participant'] = participant_name\n",
    "# numeric_means['Session'] = session_name\n",
    "# all_means.append(numeric_means)  # Append to the global all_means list\n",
    "\n",
    "# Log the result\n",
    "\n",
    "\n",
    "# def create_geodata(geodata):\n",
    "#    \"\"\"Compute UTCI across the whole time series.\"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# MAIN SCRIPT\n",
    "# processed_participants = 0\n",
    "\n",
    "# for participant_folder in os.listdir(sourcedata):\n",
    "#     if participant_folder.startswith(\"OE\"):\n",
    "#         participant_path = os.path.join(sourcedata, participant_folder)\n",
    "#         for session_folder in os.listdir(participant_path):\n",
    "#             session_path = os.path.join(participant_path, session_folder)\n",
    "#             if os.path.isdir(session_path):\n",
    "#process_session( participant_folder, session_folder)\n",
    "\n",
    "        # processed_participants += 1\n",
    "        # if processed_participants >= 2:\n",
    "        #     break  # Stop after processing 2 participants\n",
    "\n",
    "# Save the Excel file with the updated status in the log directory\n",
    "# result_file = os.path.join(logdata, \"session_processing_results.xlsx\")\n",
    "# wb.save(result_file)\n",
    "\n",
    "# Save the mean values to a final CSV file\n",
    "# if all_means:\n",
    "#     final_means_df = pd.DataFrame(all_means)\n",
    "#     final_means_file = os.path.join(logdata, \"final_means.csv\")\n",
    "#     final_means_df.to_csv(final_means_file, index=False)\n",
    "#     print(f\"Final CSV file with mean values saved to: {final_means_file}\")\n",
    "# else:\n",
    "#     print(\"No valid data found to compute mean values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapicker.geodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strs = datapicker.selected_path.split('\\\\')\n",
    "strs[len(strs)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdata = r'c:\\EXPORT'\n",
    "final_means_file = os.path.join(logdata, strs[len(strs)-1]+'.csv')\n",
    "datapicker.geodata.to_csv(final_means_file, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Export Dataset to OGC API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = DatasetRecord(datapicker.dataset, datapicker.geodata, properties=RecordProperties(\n",
    "    title='<City> Outdoor Walk: <CityRegion> Subject <ID>',\n",
    "    description='Outdoor walk data collection',\n",
    "    license='CC BY-NC 4.0',\n",
    "    tool='Bonsai',\n",
    "    keywords=['<City>', 'Outdoor', 'Walk', 'Microclimate', 'Biosignals'],\n",
    "    contacts=[\n",
    "        Contact(\n",
    "            name='Your Name',\n",
    "            institution='Your Institution',\n",
    "            email='youremail@yourdomain.com'\n",
    "        )\n",
    "    ],\n",
    "    themes=[]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpath = Path(record.id)\n",
    "export_geoframe_to_geojson(datapicker.geodata, rpath.with_suffix('.geojson'))\n",
    "with open(rpath.with_suffix('.json'), 'w') as f:\n",
    "    f.write(record.to_json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
